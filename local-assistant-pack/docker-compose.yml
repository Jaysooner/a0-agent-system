version: "3.9"
services:
  pgmemory:
    image: ankane/pgvector:latest
    container_name: a0-pgmemory
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-a0}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-a0pass}
      POSTGRES_DB: ${POSTGRES_DB:-a0memory}
    ports:
      - "5432:5432"
    volumes:
      - pgmemdata:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/01_init.sql:ro

  api:
    build: ./server
    container_name: a0-local-assistant
    env_file: .env
    depends_on:
      - pgmemory
    ports:
      - "8088:8088"

  # Optional local model (uncomment when you have weights)
  # vllm:
  #   image: vllm/vllm-openai:latest
  #   runtime: nvidia
  #   environment:
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   ports:
  #     - "8000:8000"
  #   volumes:
  #     - ./models:/models
  #   command: >
  #     --model /models/${LOCAL_MODEL:-Llama-3.1-8B-Instruct}
  #     --dtype auto
  #     --gpu-memory-utilization 0.92
  #     --max-model-len 32768
  #     --tensor-parallel-size 1

volumes:
  pgmemdata:
